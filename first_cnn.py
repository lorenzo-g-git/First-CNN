# -*- coding: utf-8 -*-
"""first CNN

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1L93E2kkt8YC6QAFILV-S3CYDvkQ-f7qU

**Prima CNN per il riconoscimento di immagini**
"""



import pandas as pd
import tensorflow as tf

#importo un dataset di default da keras
from keras.datasets import cifar10

# setto i dati di training ed i dati di test in cifar
(X_train, Y_train), (X_test, Y_test)=cifar10.load_data()

#comando da ricordare per caricare i dati

# Commented out IPython magic to ensure Python compatibility.
# importo uno strumento che mi permetta di visualizzare le immagini huma-like
import matplotlib.pyplot as plt
# %matplotlib inline 
#dice al compilatore di stamparmi l'immagine come immagine

#mi esploro una delle immagini del dataset
img=plt.imshow(X_train[1])

# voglio sapere a quale label corrisponde l'immagine che ho creato
print('The label is:', Y_train[1])

# avere dei label numerici non mi piace molto li converto in una matrice di label
#uso il metodo one-hot encoding per 10 classi
import keras
y_train_one_hot = keras.utils.to_categorical(Y_train, 10)
y_test_one_hot = keras.utils.to_categorical(Y_test, 10)

# procedo allo scaling dei dati per averli in [0,1]
# nel mio dataset i pixels sono in [0,255] mi basta normalizzare 
x_train = X_train.astype('float32')
x_test = X_test.astype('float32')
x_train = x_train / 255
x_test = x_test / 255

#eseguo un controllo
x_train[0]

"""**Creazione del modello**"""

# importo la struttura da keras
#uso Sequential
from keras.models import Sequential
from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D

model = Sequential()

# aggiungo un layer alla volta
model.add(Conv2D(32, (3, 3), 
                 activation='relu', 
                 padding='same', 
                 input_shape=(32,32,3)))

#secondo strato
model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))

#terzo strato max-pooling
model.add(MaxPooling2D(pool_size=(2, 2)))

# strato di dropout  con propbabilità di 1/4 per previnire l'over fitting
model.add(Dropout(0.25))

# aggiungo i prossimi 4 strati 
# sono simi ai primi cambia solo la profondità : 64 vs 32
model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))
model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.25))

# aggiungo un flattern layer per ridurre la struttura cubica della CNN
model.add(Flatten())

# aggiungo uno strato dense con 512 neuroni
model.add(Dense(512, activation='relu'))
# aggiungo un altro drpout con prob 0,5
model.add(Dropout(0.5))
# e l'ultimo strato dense con la softmax
model.add(Dense(10, activation='softmax'))

"""**Configuro il modello**"""

# configuro la loss function , l'ottimizzatore etc
model.compile(loss='categorical_crossentropy',
              optimizer='adam',
              metrics=['accuracy'])

"""**Training del Modelloo**"""

# avvio il training del modello 
# scelgo 20 epochs
hist = model.fit(x_train, y_train_one_hot, 
           batch_size=32, epochs=20, 
           validation_split=0.2)
# 0.2 ci dice quanto del nostro data set sarà usato come validation
# non ho bisogno di fare lo splitting data

# valutiamo il modello 
model.evaluate(x_test, y_test_one_hot)[1]

#salviamo il modello
model.save('my_cifar10_model.h5')

# ogni volta che vorrò potrò reimportare il modello
#from keras.models import load_model
#model = load_model('my_cifar10_model.h5')